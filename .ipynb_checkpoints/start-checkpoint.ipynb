{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/znazari/geneformer_shared_copy/lib/python3.10/site-packages/anndata/utils.py:434: FutureWarning: Importing read_csv from `anndata` is deprecated. Import anndata.io.read_csv instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/znazari/geneformer_shared_copy/lib/python3.10/site-packages/anndata/utils.py:434: FutureWarning: Importing read_excel from `anndata` is deprecated. Import anndata.io.read_excel instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/znazari/geneformer_shared_copy/lib/python3.10/site-packages/anndata/utils.py:434: FutureWarning: Importing read_hdf from `anndata` is deprecated. Import anndata.io.read_hdf instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/znazari/geneformer_shared_copy/lib/python3.10/site-packages/anndata/utils.py:434: FutureWarning: Importing read_loom from `anndata` is deprecated. Import anndata.io.read_loom instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/znazari/geneformer_shared_copy/lib/python3.10/site-packages/anndata/utils.py:434: FutureWarning: Importing read_mtx from `anndata` is deprecated. Import anndata.io.read_mtx instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/znazari/geneformer_shared_copy/lib/python3.10/site-packages/anndata/utils.py:434: FutureWarning: Importing read_text from `anndata` is deprecated. Import anndata.io.read_text instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/znazari/geneformer_shared_copy/lib/python3.10/site-packages/anndata/utils.py:434: FutureWarning: Importing read_umi_tools from `anndata` is deprecated. Import anndata.io.read_umi_tools instead.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scanpy as sc\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/projects/bioinformatics/DB/scRNAseq_parkinson\"\n",
    "# the full path to the .h5ad file\n",
    "h5ad_path = os.path.join(input_dir, \"dataset.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size in gigabytes: 28.45 GB\n"
     ]
    }
   ],
   "source": [
    "# Get the size in bytes\n",
    "size_bytes = os.path.getsize(h5ad_path)\n",
    "\n",
    "# Convert to a more readable unit (e.g., MB or GB)\n",
    "\n",
    "size_gb = size_bytes / (1024 * 1024 * 1024)\n",
    "\n",
    "print(f\"Size in gigabytes: {size_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size issue \n",
    "That file size of 28.45 GB for a single-cell RNA-seq .h5ad dataset is very large and will likely pose significant computational challenges for a standard analysis,\n",
    "especially when using a Transformer-based model like GenFormer.\n",
    "\n",
    "Memory (RAM): A 28 GB .h5ad file, which typically contains a sparse matrix of UMI counts, will require a substantial amount of RAM when loaded and processed. When the data is converted to a dense matrix or intermediate processing steps are performed (like calculating nearest neighbors, running PCA, etc.), the memory footprint can easily exceed 100-200 GB. If you don't have access to a high-memory computing environment (e.g., a powerful server or cloud instance), the analysis will crash.\n",
    "\n",
    "Processing Time: Even with sufficient RAM, a dataset of this size (likely involving millions of cells) will result in long processing times for any single-cell workflow, particularly for computationally intensive steps like training a large neural network model such as GenFormer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File to process: /projects/bioinformatics/DB/scRNAseq_parkinson/dataset.h5ad\n",
      "Successfully loaded AnnData in memory-safe (backed) mode.\n",
      "Data dimensions (Cells, Genes): (2096155, 17267)\n",
      "\n",
      "Starting conversion to Zarr at: /projects/bioinformatics/DB/scRNAseq_parkinson/dataset.zarr...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import anndata\n",
    "import shutil\n",
    "\n",
    "# --- Configuration ---\n",
    "input_dir = \"/projects/bioinformatics/DB/scRNAseq_parkinson\"\n",
    "h5ad_path = os.path.join(input_dir, \"dataset.h5ad\")\n",
    "zarr_path = os.path.join(input_dir, \"dataset.zarr\") # The new Zarr directory\n",
    "\n",
    "print(f\"File to process: {h5ad_path}\")\n",
    "\n",
    "try:\n",
    "    # 1. Load the AnnData object in 'backed' mode\n",
    "    # This reads metadata but keeps the 28 GB expression matrix on disk.\n",
    "    adata_h5ad = anndata.read_h5ad(h5ad_path, backed='r')\n",
    "    print(\"Successfully loaded AnnData in memory-safe (backed) mode.\")\n",
    "    print(f\"Data dimensions (Cells, Genes): {adata_h5ad.shape}\")\n",
    "\n",
    "    # 2. Cleanup: Remove existing Zarr directory to ensure a clean start\n",
    "    if os.path.exists(zarr_path):\n",
    "        print(f\"Removing existing Zarr directory at {zarr_path}\")\n",
    "        shutil.rmtree(zarr_path)\n",
    "\n",
    "    # 3. Write to Zarr\n",
    "    # The 'chunks=True' argument tells anndata to chunk the data efficiently.\n",
    "    # Note: If you get an 'overwrite' error, remove 'overwrite=True' (older anndata version).\n",
    "    print(f\"\\nStarting conversion to Zarr at: {zarr_path}...\")\n",
    "    try:\n",
    "        adata_h5ad.write_zarr(zarr_path, chunks=True, overwrite=True)\n",
    "    except TypeError:\n",
    "        # Fallback for older anndata versions without the 'overwrite' parameter\n",
    "        adata_h5ad.write_zarr(zarr_path, chunks=True)\n",
    "\n",
    "    print(\"Conversion complete! The scalable Zarr format has been created.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during loading or conversion: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Geneformer-shared-MyCopy",
   "language": "python",
   "name": "geneformer_shared_copy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
